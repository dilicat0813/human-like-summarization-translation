{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f327e7",
   "metadata": {},
   "source": [
    "# OpenAPI를 이용한 논문, 기사, 글 요약 및 번역\n",
    "\n",
    "https://jehyunlee.github.io/2022/07/02/Python-DS-106-aaicon/\n",
    "\n",
    "### Reference\n",
    "\n",
    "```\n",
    "이제현, 유시현, 김창기, 김현구, \"Open API를 활용한 고속 논문 분석\",\n",
    "실용인공지능학회지 vol.1 p.9, 2022\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df051431",
   "metadata": {},
   "source": [
    "## API 키 발급\n",
    "\n",
    "- RapidAPI : https://rapidapi.com/developer/new\n",
    "- 네이버 : https://developers.naver.com/apps/#/register?api=ppg_n2mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b204963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rapidapi_key = 'ac7a118e41msh6fa77e673997426p1860c2jsn130536d944bf'\n",
    "naver_client_id = 'JnlJAvl5Qc2Hud9taeOP'\n",
    "naver_client_secret = 'DFzwkcft1d'\n",
    "#파파고 1일 10,000글자 무료\n",
    "#rapid --> 1개월 100개 무료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b1efd",
   "metadata": {},
   "source": [
    "# TLDRThis\n",
    "\n",
    "- https://rapidapi.com/tldrthishq-tldrthishq-default/api/tldrthis/\n",
    "\n",
    "---\n",
    "\n",
    "## 요약의 종류\n",
    "\n",
    "1. Abstractive(Human-like) summarization\n",
    "\n",
    "> Abstractive summarization(생성 요약)은 기존 Input text를 그대로 인용하지 않고, 기존의 내용을 새롭게 re-phrasing 하여 Summary를 생성하는 요약 모델입니다.\n",
    "\n",
    "2. Extractive summarization\n",
    "\n",
    "> 반면에 Extractive summarization(추출 요약)은 기존 Input text에 존재하는 중요한 단어를 그대로 사용하여 Summary를 생성하는 요약 모델입니다.\n",
    "\n",
    "출처 : https://supkoon.tistory.com/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69898271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61573ca4",
   "metadata": {},
   "source": [
    "### 예시 논문\n",
    "\n",
    "Attention Is All You Need\n",
    "- 페이지 : https://arxiv.org/abs/1706.03762\n",
    "- 본문(pdf) : https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600ad29",
   "metadata": {},
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a7b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detail': [{'loc': ['body', 'url'],\n",
      "             'msg': 'invalid or missing URL scheme',\n",
      "             'type': 'value_error.url.scheme'}]}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://tldrthis.p.rapidapi.com/v1/model/abstractive/summarize-url/\"\n",
    "\n",
    "payload = {\n",
    "    \"url\": \"test.pdf\", # 주소\n",
    "    \"min_length\": 100, # 최소 길이\n",
    "    \"max_length\": 300, # 최대 길이\n",
    "    \"is_detailed\": False # 한 문장으로 반환할 것인지 여부\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"X-RapidAPI-Key\": rapidapi_key,\n",
    "    \"X-RapidAPI-Host\": \"tldrthis.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9911dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(summary)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "summary = response.json()['summary'][0].strip()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c4aa4",
   "metadata": {},
   "source": [
    "## 번역\n",
    "\n",
    "네이버 파파고 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bc6a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': {'@service': 'naverservice.nmt.proxy',\n",
      "             '@type': 'response',\n",
      "             '@version': '1.0.0',\n",
      "             'result': {'dict': None,\n",
      "                        'engineType': 'UNDEF_MULTI_SENTENCE',\n",
      "                        'pivot': None,\n",
      "                        'srcLangType': 'en',\n",
      "                        'tarDict': None,\n",
      "                        'tarLangType': 'ko',\n",
      "                        'translatedText': '우리는 주의 메커니즘만을 기반으로 하는 새로운 간단한 네트워크 '\n",
      "                                          '아키텍처인 트랜스포머를 제안한다. 두 가지 기계 번역 작업에 '\n",
      "                                          '대한 실험은 이러한 모델이 품질 면에서 우수하면서도 병렬화가 더 '\n",
      "                                          '가능하고 교육하는 데 훨씬 적은 시간이 필요하다는 것을 '\n",
      "                                          '보여준다. Transformer는 훨씬 더 많은 병렬화를 '\n",
      "                                          '가능하게 하며 8개의 P100 GPU에서 12시간 정도 교육을 '\n",
      "                                          '받은 후 번역 품질에서 새로운 최첨단 기술에 도달할 수 '\n",
      "                                          '있습니다. 순차 연산을 줄이는 목표는 확장 신경 GPU[16], '\n",
      "                                          'ByteNet[18] 및 ConvS2S의 기초를 형성한다.'}}}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "\n",
    "payload = {\n",
    "    \"source\": \"en\",\n",
    "    \"target\": \"ko\",\n",
    "    \"text\": summary,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"X-Naver-Client-Id\": naver_client_id,\n",
    "    \"X-Naver-Client-Secret\": naver_client_secret,\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e204b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리는 주의 메커니즘만을 기반으로 하는 새로운 간단한 네트워크 아키텍처인 트랜스포머를 제안한다. 두 가지 기계 번역 작업에 대한 실험은 이러한 모델이 품질 면에서 우수하면서도 병렬화가 더 가능하고 교육하는 데 훨씬 적은 시간이 필요하다는 것을 보여준다. Transformer는 훨씬 더 많은 병렬화를 가능하게 하며 8개의 P100 GPU에서 12시간 정도 교육을 받은 후 번역 품질에서 새로운 최첨단 기술에 도달할 수 있습니다. 순차 연산을 줄이는 목표는 확장 신경 GPU[16], ByteNet[18] 및 ConvS2S의 기초를 형성한다.\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['message']['result']['translatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b8837",
   "metadata": {},
   "source": [
    "## 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ef2e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_and_translate(article_url, min_length=100, max_length=300):\n",
    "    url = \"https://tldrthis.p.rapidapi.com/v1/model/abstractive/summarize-url/\"\n",
    "\n",
    "    payload = {\n",
    "        \"url\": article_url, # 주소\n",
    "        \"min_length\": min_length, # 최소 길이\n",
    "        \"max_length\": max_length, # 최대 길이\n",
    "        \"is_detailed\": False # 한 문장으로 반환할 것인지 여부\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"X-RapidAPI-Key\": rapidapi_key,\n",
    "        \"X-RapidAPI-Host\": \"tldrthis.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "    summary = response.json()['summary'][0].strip()\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "\n",
    "    payload = {\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"ko\",\n",
    "        \"text\": summary,\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "    \n",
    "    return response.json()['message']['result']['translatedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88afea5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리는 주의 메커니즘만을 기반으로 하는 새로운 간단한 네트워크 아키텍처인 트랜스포머를 제안한다. 두 가지 기계 번역 작업에 대한 실험은 이러한 모델이 품질 면에서 우수하면서도 병렬화가 더 가능하고 교육하는 데 훨씬 적은 시간이 필요하다는 것을 보여준다. 트랜스포머는 훨씬 더 많은 병렬화를 가능하게 하며 8개의 P100에서 12시간 동안만 교육을 받은 후 번역 품질에서 새로운 기술에 도달할 수 있습니다.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_and_translate(\"https://arxiv.org/pdf/1706.03762.pdf\", 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52a35173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EfficientNet-B7은 ImageNet에서 최고 84.3%의 정확도를 달성하는 동시에 기존 최고의 ConvNet보다 8.4배 작고 추론 속도가 6.1배 빠르다. 우리의 EfficientNets는 다른 ConvNets를 크게 능가한다. 이전 작업에서는 깊이, 너비, 이미지 크기 등 세 가지 차원 중 하나만 스케일링하는 것이 일반적이다. 단순하지만 매우 효과적인 복합 계수를 사용하여 깊이/폭/해상도의 모든 차원을 균일하게 확장하는 단순하지만 효과적인 복합 스케일링 방법을 제안한다. 예를 들어, 우리가 2N배 더 많은 계산 자원을 사용하고 싶다면, 우리는 단순히 원래 모델에서 네트워크를 작은 그리드만큼 늘릴 수 있다.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_and_translate(\"https://arxiv.org/pdf/1905.11946.pdf\", 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fefce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
